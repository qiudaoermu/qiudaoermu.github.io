---
title: "📣📣ph-d-vs-Engineer"
date: 2022-06-20
tags: 
- 开发日常
---
**ph.d 翻译为哲学家，指在某个领域可以建立新的世界体系的人。 一般意义上说应该是发明家，cs ph.d 不同于一般的面向CV开发工程师，其面相的领域需要开辟，探索，发现。**

## 主要研究方向

计算机方向总体上分三类：

**Fundamental Theory Of Computer Science**，以我的了解和数学关系比较大 ，建立新的世界架构，比如图灵机。  **Computer Engineering**：在当前计算机体系前建立的软硬件系统，操作系统，计算机语言，编译器等。  **Applications**：如何利用计算机完成实现交叉工作，比如AI，各种领域软件开发。

内容广泛，不仅仅包含数学，还会涉及材料，物理学，化学等等，而且和不同领域都存在交叉。

![The Map of Computer Science](https://upload-images.jianshu.io/upload_images/15312191-c02181a7e8afa848.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240) 

### 1\. Fundamental Theory Of Computer Science（硬核）

#### 1.1 System

Systems的内容十分广泛，包括OS, Architecture, Network等等，比如特定场景操作系统，并行高性能计算机，分布式系统，存储系统和编程系统，文件系统、云系统，高性能系统计算、系统的可靠性、安全性，测量与性能分析。

顶会：SOSP，OSDI，这两个是OS最好的会议，每两年开一次，轮流开，比如今年是OSDI，那么明年就是SOSP。由于这两个会议方向很广，因此影响很大。

#### 1.2 Computer Architecture

美国斯坦福大学最近在一份报告中分析了过去 20 年间出现的几乎所有的处理器，发现处理器性能提高了约 1 万倍。该报告进一步指出，在 1 万倍的性能提升中，半导体工艺贡献了 100 多倍，计算机体系结构贡献了 80 多倍，可见计算机结构对提升计算机性能的重要性。

计算机系统结构是计算机的机器语言程序员或编译程序编写者所看到的外特性。所谓外特性，就是计算机的概念性结构和功能特性，主要研究计算机系统的基本工作原理，以及在硬件、软件界面划分的权衡策略，建立完整的、系统的计算机软硬件整体概念。

🟩 **说人话就是研究计算机硬件体系的。**

##### 未来计算机模型

现代计算机自问世以来已历经50余年的历史，但计算机所遵循的基本结构形式始终是冯·诺依曼机结构。它的基本结构特征是“**共享数据和串行执行**”的计算机模型。  按照这种结构，程序和数据放在共享存储器内，CPU取出指令和数据进行相应的计算，因此CPU与共享存储器间的信息通路成为影响系统性能的“瓶颈”，芯片性能提升速度远高于存储性能的提升速度。多年来在并行计算机结构及处理的研究已经取得了很多成果，如阵列机、流水机、向量机等，使计算速度有了很大提高，但就本质上仍无法克服冯·诺依曼机结构上的缺陷。

1.目前 CPU 的处理速度和内存容量的成长速率要远大于两者之间的流量，将大量数值从内存搬入搬出的操作 占用了 CPU 大部分的执行时间，也造成了总线的瓶颈。

2.程序指令的执行是串行的，由程序计数器控制，这样使得即使有关数据已经准备好，也必须遵循逐条执行指令序列，影响了系统运行的速度；

3.存储器是线性编址，按顺序排列的地址访问，这是有利于存储和执行机器语言，适用于数值计算。但高级语言的存储采用的是一组有名字的变量，是按名字调用变量而非按地址访问，且高级语言中的每个操作对于任何数据类型都是通用的，不管采用何种数据结构，多维数组、二叉树还是图，最终在存储器上都必须转换成一维的线性存储模型进行存储。这些因素都导致了机器语言和高级语言之间存在很大的语义差距，这些语义差距之间的映射大部分都要由编译程序来完成，在很大程度上增加了编译程序的工作量。

4.冯·诺依曼体系结构计算机是为**逻辑和数值**运算而诞生的，它以 CPU 为中心，I/O 设备与存储器间的数据传送都要经过运算器，在**数值处理**方面已经达到很高的速度和精度，但对**非数值**数据的处理效率比较低，需要在体系结构方面有革命性突破。

在非冯领域，包括近年来的出现的量子计算机，光子计算机，神经计算机（Neural computer）等，其中量子芯片已经面世，中国科大潘建伟团队构建起76个光量子的量子计算原型机“九章”，处理高斯玻色取样的速度比目前最快的超级计算机快一百万亿倍。如果量子计算机可以普及，计算机系统、计算机语言、软件体系，从业人员培养体系都会被推翻重来。

##### 特定场景芯片

比如在人工智能芯片方面，谷歌开发了用于AI计算高性能硬件**TPU**，Intel推出了针对深度学习市场的众核CPU**Knights Mill**，英伟达推出了**GPGPU**，而且还有了**DGX-1**这样的产品；在互联网大规模核心推荐算法场景，百度推出的**“百度昆仑1”**已在百度搜索引擎、小度等业务中部署超过2万片；自动驾驶领域，特斯拉发布了用于自动驾驶深度学习和解决带宽瓶颈的**D1**芯片。  ![](https://upload-images.jianshu.io/upload_images/15312191-623d3cda0454ca0e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240) 

针对高并发、高性能和高效需求，阿里平头哥发布了为云而生**倚天710**，**CIPU**，阿里云飞天+CIPU体系的推出，针对性地解决了云资源的多个痛点。首先，该体系通过全硬件虚拟化和转发加速，将存储时延降至最低30us（PLX），IOPS高达300万，存储带宽可达200 Gbps，全面超越市面上所有云产品；同时，该体系还将数据中心内的基础带宽从100G升级至200G，VPC的PPS转发性能从2000万提升至4000万，网络时延从22us降低至16us，RDMA协议下更可低至5.5us。在计算能力方面，新体系实现了单容器虚拟化消耗减少50%，虚拟化容器启动速度快350%。主流通用计算场景下，**Nginx**性能提升了89%，**Redis**性能提升了68%、**MySQL**提升了60%。

该领域的四大国际顶级会议: **ISCA(偏芯片领域), HPCA, MICRO, ASPLOS**。

ps: 对于体系结构领域的应届毕业生来说，市场上有大致上三种工作可以选，一种是去做金融，高频交易之类，薪水很高；另一种是去做机器学习，利用体系结构领域的知识和技能去做机器学习应用的调优，也是薪水很高；比较符合体系结构传统的工作，例如去传统的芯片设计公司做芯片。

在半导体集成电路领域，按照中国当前的国情，这个产业将迎来爆发阶段。据报道，在过去的四个季度，全球20个增速最快芯片公司，19个来自中国。

比如前一段时间看到一直关注的频道老石谈芯的博主**石侃**(伦敦帝国理工学院电子工程系博士、高级 FPGA 研发工程师)宣布加入国内某芯片大厂。相信随着更多尖端人才的回流，国家战略倾斜，中国的计算机技术会越来越强大。

#### 1.3 嵌入式实时计算机

主要研究嵌入式的，希望未来的一天计算机可以植入人的大脑，微型计算机像手机一样进去大众生活中，就像科幻片里，召之即来挥之即去。

#### 1.4 Computer Networks

Networking甚至包括Telecommunication。这个范围可以说是非常的大。网络应用、网络协议、网络通信、网络理论、网络安全、加密解密、路由算法、甚至编解码都是需要学习的学科。

##### 1.5 Mobile computing

移动计算是随着移动通信、互联网、数据库、分布式计算等技术的发展而兴起的新技术。移动计算技术将使计算机或其它信息智能终端设备在无线环境下实现数据传输及资源共享。它的作用是将有用、准确、及时的信息提供给任何时间、任何地点的任何客户。这将极大地改变人们的生活方式和工作方式。

#### 1.6 计算机理论

计算机理论涵盖的领域十分广泛，包括算法和数据结构、计算复杂性、密码学、计算几何、组合学、随机与去随机化、算法博弈论和量子计算等。

计算机理论科学是完全偏向理论的学科，研究的不只是算法，更加重要的是算法的有效性和可行性。

理论计算机科学领域有两大顶会，一个是ACM（美国计算机学会）的STOC，另外一个是IEEE（国际电气和电子工程师协会）的FOCS。

##### 1.6.1 Algorithms & complexity

计算机领域的算法的创新改进，比如华为的俄罗斯小伙，对数学问题的突破，使得华为基站大幅度领先。  最近看了一篇文章，某个团队在最大流问题利用这个问题，算法获突破性进展。

##### 1.6.2 Cryptography

密码学是研究编制密码和破译密码的技术科学。研究密码变化的客观规律，应用于编制密码以保守通信秘密的，称为编码学；应用于破译密码以获取通信情报的，称为破译学，总称密码学。

举个🌰：md5加密相信大家都听过，用过。发明者是[Ronald Rivest](https://en.wikipedia.org/wiki/Ronald_Rivest "Ronald Rivest")教授(耶鲁大学数学专业，斯坦福大学计算机科学ph.d)，他有多项发明，比如md6，[RSA](https://en.wikipedia.org/wiki/RSA_(algorithm)) ，此外还著有书籍《Introduction to Algorithms》，2002年因RSA加密方案，获得年度图灵奖。
### 2\. Computer Engineering

软件工程/系统软件/程序设计语言。  研究用工程化方法构建和维护有效的、实用的和高质量的软件的学科。它涉及程序 设计语言、数据库、软件开发工具、系统平台、标准、设计模式等方面。
典型的软件有电子邮件、嵌入式系统、人机界面、办公套件、**操作系统**、**编译器**、**数据库**等。这个专业比较灵活，可以说是为程序员服务的程序员。



### 3.Applications

#### 3.1 AI

![](https://upload-images.jianshu.io/upload_images/15312191-924211e3319856b7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240) 

##### AI解放生产力

随着计算机硬件性能的巨大提升，曾经沉寂一时的AI卷土重来。Ai大幅度提高生产力，取代人类工作，如果你的工作符合以下特征，你的工作被机器人取代的概率非常大：大量的重复性劳动，每天上班无需过脑，经由训练即可掌握的技能，工作空间狭小，坐在格子间里，不闻天下事。拜人工智能所赐，未来肯定会有人类从事的工作会被消灭。

AI细分为机器学习和数据挖掘，人工智能，计算机视觉(感知)，自然语言处理，网络信息收集。

Ai涉及到的具体场景包括，智能机器人，战争AI，智慧医疗，自动驾驶，语音识别。在物流行业中，无人货仓，智能分拣系统，客服系统也都已经充满了AI的身影。

##### AI的缺陷

**1.复杂性问题**  很遗憾，截至目前，人工智能(AI)基本没有带来颠覆性的产业价值。原因也很简单，AI目前不具备处理世界“**复杂性**”的能力。如何判断AI+是否可以为一个产业带来颠覆性影响与价值，关键在于AI能否处理这个产业所在供给需求的复杂性。

复杂性是系统科学发展到当前阶段，人类对系统属性的本质认识。从对自然现象的解释，到对生物进化的理解，再到对社会领域人造工程系统的构建，以及对经济发展的管理，人们开始意识到再这些探索活动背后都面临着相同的敌人，那就是“复杂性”。 现在全球对复杂性没有一致的定义，但对其属性倒是有基本统一的认知：**非线性、混沌、涌现性、自组织、自适应性。**

除此以外，复杂性还有3个层次：**自组织、自适应和决策博弈**。第一层次是自组织，指无机系统演化遵从自然规则，第二层次是指生物系统演化遵循目的导向的自适应性，而最高层次是人类处理事情时的决策博弈过程。因此所谓复杂性，可以理解成无机世界的自组织、有机世界的自适应以及人类的心理决策博弈。

每一个产业都有其自身的自组织、自适应和决策博弈，AI+必须直面这个复杂性，才能创造增量价值。以肿瘤治疗为例，AI可以帮助人类克服肿瘤吗？那么AI首先就要直面**肿瘤的复杂性**，！AI必须理解生命是如何在内在机制的驱动下，如何自行从简单向复杂、从粗糙向细致方向发展。她必须理解生命系统如何对外界环境干扰或内部变化做出自我适应。她必须考虑肿瘤自身与人免疫系统的博弈，理解肿瘤和人免疫系统的相互博弈。

以上述标准看，在多个行业，AI+仅仅解决了“点”的问题，而没有触及系统复杂性，更谈不上解决复杂性问题，自然无法创造增量价值，颠覆传统模式。在未来，谁先掌握解决复杂性的AI，谁才能真正运用AI，为产业赋能。  **2.算力问题**  传统计算机架构导致的性能问题，无法满足当前算力的需要。  虽然近些年基础算力、智能算力和超算算力都有很大程度的增长，未来5年全球的增速甚至超过50%，但与日益复杂的算法模型和快速增长的现实需求而言，仍然存在较大的缺口。同时，存算一体架构、量子计算、光子计算和类脑计算芯片尚处于实验室的研发阶段，离大规模商业化还有较长的时间，无法以技术革命的方式实现跨越式发展。虽然，诸如商汤科技、华为等头部公司采取了建立人工智能计算中心（AIDC）的方式，来满足未来智能计算需求的快速增长；我国神威、天河、曙光三台E级超算系统的研制工作也在逐步推进，很多国内的硬件公司着手计算机硬件的国产化替代。但从短期来看，算力将会是一个制约人工智能技术发展的现实困难。

比如无人驾驶至今无法真正投入使用，很大大神从工业界重返学术界的现象很大，比如离开谷歌的李飞飞。AI浪潮已经来袭了3次，海水退去，不知道能否游上岸，未来AI能走多远，仍是未知数。

**顶会**：AI顶会最为熟知的人工智能领域最核心的四大顶会AAAI、IJCAI、ICML和NIPS，以及作为计算机视觉和自然语言为代表的CVPR和ACL这两大学术会议，也涌现了许多“后起之秀”，比如仅创立六年却有深度学习顶会“无冕之王”之称的ICLR，还有创办于1996年的大有赶超ACL之势的自然语言处理领域顶会EMNLP，这些“新星会议”的崛起，使得AI领域的会议呈现出亮点纷呈、多面开花的局面。

#### 3.2 生物医疗

比如计算机在医疗中的应用，Ai诊病，通过提取病人特征，快速诊断，缩短医生诊疗时间。提前预测病人病情，指定医疗方案，AI筛选药物，制药，医疗报告生成。使用人机接口，通过脑电波控制机械驱体等。

目前AI在医疗领域得到广泛的应用：例如Abundy的癌症诊疗系统，在2分钟可以检测完130张癌症片子，而一个经验丰富的医生2分钟只能看一个。

广州祈福医院有一个“沃森诊室”，机器人沃森可以只用10秒就能阅读3469本医学专著和10余万份临床报告。医生只需在机器上录入患者相关信息，短短几十秒内一份70页至100页的治疗报告就会生成。虽然目前AI只能充当医生的助手，两者相结合，给患者提供最大的保障，然而人工智能机器人将会逐步取代那些普通医生。

#### 3.3 robot

![](https://upload-images.jianshu.io/upload_images/15312191-f4b808c16db78ee7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

  机器人研究方面比较广，目前美国是该领域的领跑者，比如战斗机器人，包括无人机，比较常见的任务包括侦察，排雷等，如美国波士顿公司的BigDog和阿特拉斯，部分型号的机器人装备了机枪等攻击性武器。Big Dog还可以帮助美军承担大重量物品的长途搬运工作，能够克服各种路面的异常情况，可以说是现代版的"木牛流马"，可能是诸葛亮提供的思路🤣。

工业机器人，比如汽车生产组装流水线，无需人工干预，各种机器人在指令下，协同完成汽车各个部位的组装。甚至无人工厂，比如小米手机工厂，其在世界智能大会中展示的宣传片显示，未来该工厂将24小时熄灯生产，无人干预，甚至一秒钟就能生产一部手机。

家庭护理机器人，就像保姆一样，完成餐桌碗碟的摆放，自动挑选放入洗碗机，感觉这个可以入手一台啊。

有些机器人可以代替人工的高危作业，比如焊接机器人，海底探险机器人，维修机器人，等等。

机器人在未来会取代很多职业，比如快递小哥，阿里分拣机器人“小黄人"三个小时的工作量相当于100名工人一天的工作量。

#### 3.4 经济和计算

投资相关，比如利用计算机预测股市，制定投资计划，数据分析等。

一旦看好一家公司，优秀的金融分析师会提前分析迈入，帮助机构调整投资并赚取巨额的收益。随着大数据时代的来临，近年来，一种观点十分流行：量化分析师即将完全取代主观分析师，机器即将完全取代人。这是因为人类金融分析师无法跟AI抗衡了，人工智能可以深度学习，读取历史数据，预测未来市场的走向。曾有论文指出，未来20年，美国47%的工作岗位将由于自动化技术而处于“高度危险”之中，其中54%的工作岗位来自金融行业。这并不奇怪，毕竟银行和金融行业的基础就是信息处理。拥有超强速算速度的人工智能，可以更加高效帮助企业进行投资，比起传统的金融分析师更有效率。

#### 3.5 Human-computer interaction

这是一门交叉学科，涵盖艺术，设计，计算机，心理学，社会学等等学科。主要是通过过计算机输入、输出设备，以有效的方式实现人与计算机交流。

人机交互这个专业作为产品和用户之间的桥梁，已成为行业发展不可或缺的重要一环。无论是手机UI，汽车操作界面设计，用户体验，游戏设计又或是VR产业都需要这个专业的人才。

#### 3.6 Computer graphics

![](https://upload-images.jianshu.io/upload_images/15312191-6369718bc5ccfbfe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240) 

计算机图形学(Computer Graphics，简称CG)是一种使用数学算法将二维或三维图形转化为计算机显示器的栅格形式的科学。

简单地说，计算机图形学的主要研究内容就是研究如何在计算机中表示图形、以及利用计算机进行图形的计算、处理和显示的相关原理与算法。

比如元宇宙概念，AR眼镜已经可以逼真的在你眼前投射大屏，声临其境的感受3d环境，这种在科幻电影中才能出现的场景已经成为现实。

![](https://upload-images.jianshu.io/upload_images/15312191-507b7603dd2b9c7b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

  ps: 以上只是几个大类分类，计算机的蓬勃发展，对人类社会产生巨大冲击，计算机未来一百年会发展成什么样，应该是一件很有趣的事。

## Engineer VS cs phd

![](https://upload-images.jianshu.io/upload_images/15312191-65d3942dd445f8c9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240) 

### 学术界VS工业界

phd基本上工作流程是做研究，找方向，做实验，发paper，不需要你每天没月都有产出，因为科研是一个long term的工作，自由度很高。

一般程序员日常操作是需要写各种report，周报、月报、日报。基本工作是发现问题，百度一下，复制，整合，模仿，技术解决方案基本是面向API开发❓。

是不是有时候突然会感觉自己做的事很无聊（没错说的就是我!!🥲 )，复制粘贴本身就很无聊；应用层的这种工作对一些人来说无法产生有效刺激，而且更可怕的是，长期在这种模式下工作，生产力会一直停留在某个层次，无法提高，准确来说，应该是 3-6 个年后，他们的生产力集体达到了一个“平台期”，再也无法增长。

无聊的另一个来源是，总觉得自己的工作很死板总是一个老套路，没有什么挑战性，没有那种intellectual challenge在里面。公司工作，有时候会碰到一些挑战，比如说原来一个星期写完的代码，要让你两天写完，但是这样的挑战并不是intellectual challenge。

### 转换思维

工业界里，我们应该更多突破固定思维，少一些follow up，多一些new idea，一些问题除了现有的解决方案，能不能想出别的方法呢，即使不是更好的解法，具体问题要敢于质疑权威，走出自己的路。

一个任务完成后，我们的认知、工程化能力、知识圈层，有没有向外围扩展。宇宙之大，知识世界之辽阔，穷极一生也不可能全部学完。与其被动接受，不如换种学习方式，去创造，融会贯通，培养自己的创新能力。

工程师是一个非常需要创造力的工作岗位🤔。如果只局限在自己的岗位设定而没有更多思考，机械式完成任务的结果就是只能自嘲为“新生代的代码农民工”。只有把创造力、架构能力和学习能力都融入开发过程，才能感觉到自己的工作发挥出了工程师的真正价值，从而体验到研发的乐趣。

### Figure Out Your Life

大多数人都读不了硕士博士，没有机会做学术，但是这种作业方式特别值得我们学习。技术就是创新，不是学习API和各种知识，大多数人都不是搞技术的，而是软件操作技工、技术搬运工，这是一个痛苦又不得不接受的现实。 很多人入行的时候希望搞技术，去改变一些东西，最后确成了一个一年经验用N年，面向API开发，停留在倦怠期，迷失在自我循环世界的老油条。

选择学术界还是工业界，取决你的性格，如果你天生不喜欢被约束，喜欢搞自己的事情，那么科研可能更适合你。

有可能我们不知道自己做什么，慢慢找到自己想做的事，figure out what you want。  只要你有兴趣想学总归是好的。我只想说人生可能都会走点弯路，都是在不断寻找正确的路。

### 对于读博士的一些误解

**1.“读博和科研只适合绝顶聪明或成绩非常好的人。”**

这个看法是完全错误的，如同“演员只有非常有表演天赋的人才能当”一样是个伪命题。你如果认为大家心目中的学术大牛都是绝顶聪明的人，就好比说经常出现在新浪首页或者微博热搜的那几位明星的演技都非常好一样。

在博士群体，做出顶级科研的并不都是同辈中超级聪明的人，也不一定是平均成绩点数(Grade Point Average, GPA)最高的人，更不一定是参加ACM编程竞赛的高手们，而恰恰是那些有耐心有毅力坚持去钻研的人。

很多博士生只要选好导师，选好研究方向，肯花费时间，都能做出顶尖的研究。有很多在海外学术圈颇有建树的学者当年的学习成绩并不好。  **2.“科研穷三代，读博毁一生。”**

这句话在其他领域或许是对的，但在计算机领域就是错的。在计算机领域，通过读博挣钱的大有人在！计算机学科的特性就是科研与产业结合得非常紧密。尤其是最前沿的科研，对产业有很大的推动作用，并产生经济利益。

一个典型的例子就是谷歌的创始人佩奇和布林都是博士生，也出自博士家庭。虽然他们没读完博士就去创业了（布林自称现在在职读博士），但是如果他们没有读博，那将很难开创出谷歌的核心技术。

目前业界大数据系统的宠儿Spark，就是由加州大学伯克利分校的教授和博士们开发的。首席开发者马泰扎·哈里亚(MateiZaharia)即使有挣大钱的机会，也没有完全放弃麻省理工学院的教职。

在网络技术领域，目前业界关注的核心“软件定义网络”也是教授和博士们在大学里开发出来的。谷歌、威睿(VMware)、 Databricks (Spark)、Nicira (OpenFlow)以及无数顶尖技术公司雇佣了数以千计的计算机专业毕业的博士，因为博士通常比其他雇员更接近核心技术。

如果你想实现自己的技术梦想并挣大钱，读博士是一个很好的选择。“读博就得走清贫的人生道路”是没有任何道理的。  **3.“科研做的东西大部分都是废纸，对实际一点帮助都没有。”**

这种观点在计算机领域也是不正确的。计算机科学并不是屠龙之技。今天几十亿人都离不开的计算机网络的原型就是从加州大学洛杉矶分校发展起来的，莱昂纳多·克莱洛克(LeonardKleinrock)教授在阿帕网(ARPANET)项目中开发了互联网的雏形，并在1969年发送了互联网的第一个数据包。

20世纪70年代，美国工程院院士林善成(Simon Lam)教授在他的博士论文中分析了解决链路层冲突的方法，最后被以太网采用，融入到我们的生活中。

林教授在90年代开发了安全套接层(SSL)的第一个实现系统，如今安全套接层被运用到每台电脑和手机的浏览器中。不仅是计算机网络，几乎每个计算机领域的技术都被科研引领着。

按照加州大学伯克利分校博士后研究员钱学海博士发表在《中国计算机学会通讯》(CCCF)上的文章1所说，计算机体系结构这些年的发展，都与该领域四大学术会议上的论文密不可分。

另一方面，虽然很多论文在现实世界不一定能体现直接价值，但是在写文章的过程中，你能学到很多东西，比如提出问题、解决问题、语言表达的能力，这些都让人受益无穷。

> [我为什么鼓励你读计算机专业博士](https://zhuanlan.zhihu.com/p/60308234)  [4年计算机博士读下来的一些感触](https://blog.csdn.net/ytomc/article/details/76387456)  [计算机基础问题，最大流问题获突破性进展：新算法「快得离谱」](https://www.jiqizhixin.com/articles/2022-06-14-9)  [US sanctions helped China supercharge its chipmaking industry](https://www.businesstimes.com.sg/global-enterprise/us-sanctions-helped-china-supercharge-its-chipmaking-industry)  [The Map of Computer Science](https://www.youtube.com/watch?v=SzJ46YA_RaA)  [中国计算机学会推荐国际学术会议和期刊目录](https://ccf.atom.im/)  [冯•诺依曼计算机将渐行渐远?](https://www.infoq.cn/article/2015/06/alan-turing-neumann)
